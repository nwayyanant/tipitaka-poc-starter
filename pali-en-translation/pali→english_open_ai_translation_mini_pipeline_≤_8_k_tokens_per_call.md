https://chatgpt.com/share/68b46758-38d8-8001-a700-15be02f5f803

# README â€” PÄli â†’ English Academic Translation Pipeline

á€’á€®á€…á€¬á€á€™á€ºá€¸á€€ Romanized PÄli á€…á€¬á€€á€­á€¯ **OpenAI API** á€á€¯á€¶á€¸á€•á€¼á€®á€¸ Academic English Translation á€œá€¯á€•á€ºá€–á€­á€¯á€· á€¡á€†á€„á€·á€ºá€†á€„á€·á€ºá€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€•á€¯á€¶áŠ á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá€á€²á€· á€•á€¼á€¿á€”á€¬á€™á€»á€¬á€¸áŠ á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€”á€Šá€ºá€¸á€™á€»á€¬á€¸ á€¡á€•á€¼á€Šá€·á€ºá€¡á€…á€¯á€¶á€€á€­á€¯ á€–á€±á€¬á€ºá€•á€¼á€‘á€¬á€¸á€á€šá€ºá‹

---

## á€œá€¯á€•á€ºá€†á€±á€¬á€„á€ºá€›á€™á€šá€·á€º á€¡á€†á€„á€·á€ºá€™á€»á€¬á€¸

### áá‹ Dataset á€€á€­á€¯ á€¡á€†á€„á€ºá€•á€¼á€±á€…á€½á€¬ á€…á€®á€™á€¶
- PÄli text á€–á€­á€¯á€„á€º (romanized) á€€á€­á€¯ á€…á€¬á€•á€­á€¯á€’á€º/á€…á€á€”á€ºá€‡á€¬ á€¡á€œá€­á€¯á€€á€º á€á€±á€á€»á€¬ **chunking** á€œá€¯á€•á€ºá€•á€«á‹
- Rule:
  - ~2,000â€“4,000 tokens á€á€…á€ºá€•á€­á€¯á€„á€ºá€¸á€‘á€² á€‘á€Šá€·á€ºá€á€½á€¬á€¸á€á€¬ á€¡á€†á€„á€ºá€•á€¼á€± (OpenAI GPT-4o/4.1 á€€ á€¡á€™á€»á€¬á€¸á€†á€¯á€¶á€¸ 128kâ€“1M context á€™á€›á€¾á€­á€™á€–á€¼á€…á€ºá€œá€Šá€ºá€¸, **margin á€‘á€¬á€¸á€•á€¼á€®á€¸ 8k tokens á€á€”á€·á€º** á€á€¯á€¶á€¸á€á€„á€·á€º)
  - á€…á€¬á€á€…á€ºá€•á€­á€¯á€„á€ºá€¸/á€…á€á€”á€ºá€‡á€¬á€€á€­á€¯ logical á€¡á€á€­á€¯á€„á€ºá€¸ á€™á€–á€¼á€á€ºá€–á€­á€¯á€· (translation á€™á€¾á€”á€ºá€›á€”á€º)

á€¥á€•á€™á€¬:
```
Buddhopi buddhabhÄvaá¹ƒ, bhÄvetvÄ ceva sacchikatvÄ ca; 
Yaá¹ƒ upagato gatamalaá¹ƒ, vande tamanuttaraá¹ƒ dhammaá¹ƒ.
...
```

### á‚á‹ Glossary (Academic Style Standardization) á€á€Šá€ºá€†á€±á€¬á€€á€º
- á€¡á€“á€­á€€ doctrinal terms á€€á€­á€¯ á€™á€»á€€á€ºá€™á€¾á€±á€¬á€€á€ºá€™á€‘á€½á€€á€ºá€¡á€±á€¬á€„á€º **á€á€±á€á€»á€¬á€á€­á€€á€»á€á€²á€· gloss** á€á€á€ºá€™á€¾á€á€ºá€•á€«á‹
  - paÃ±Ã±Ä â†’ wisdom  
  - saá¹…khÄra â†’ formations  
  - viÃ±Ã±Äá¹‡a â†’ consciousness  
  - dhamma â†’ the Teaching / phenomena (context-based)
- á€’á€® glossary á€€á€­á€¯ **prompt á€‘á€² á€‘á€Šá€·á€º**áŠ Model á€€á€­á€¯ á€¡á€™á€¼á€²á€á€™á€ºá€¸ á€¡á€á€¯á€¶á€¸á€á€»á€á€­á€¯á€„á€ºá€¸á€•á€« â†’ â€œTranslate PÄli into precise Academic English, always map paÃ±Ã±Ä as â€˜wisdomâ€™ etc.â€

### áƒá‹ Prompt Design
- System message á€‘á€²á€™á€¾á€¬ Academic Translation Guide á€‘á€Šá€·á€ºá€•á€«
```
You are a skilled translator. Your task is to translate Romanized PÄli texts into precise Academic English suitable for scholarly research. 
- Use established Buddhist terminology (see glossary).
- Maintain doctrinal nuance and avoid simplification.
- Output should be formal and academic in tone.
```

### á„á‹ API Call (OpenAI Responses API)
```bash
curl https://api.openai.com/v1/responses \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o",
    "input": [
      {"role": "system", "content": "...Academic style prompt..."},
      {"role": "user", "content": "Buddhopi buddhabhÄvaá¹ƒ ..."}
    ]
  }'
```

### á…á‹ Output Post-Edit
- Glossary á€¡á€á€­á€¯á€„á€ºá€¸ á€á€¯á€¶á€¸á€‘á€¬á€¸á€á€œá€¬á€¸ á€…á€…á€ºá€•á€«
- á€™á€á€„á€·á€ºá€á€±á€¬á€ºá€á€²á€· synonyms á€€á€­á€¯ regex á€”á€²á€· á€¡á€œá€­á€¯á€¡á€œá€»á€±á€¬á€€á€ºá€•á€¼á€„á€ºá€•á€«
- Human QA á€•á€¼á€”á€ºá€…á€…á€ºá€–á€­á€¯á€· flagged lines only á€‘á€¬á€¸á€•á€«

### á†á‹ Automation Workflow
-PÄli text â†’ split_chunks.py (8k tokens á€¡á€±á€¬á€€á€º)
-Chunk á€á€…á€ºá€á€¯á€á€»á€„á€ºá€¸á€…á€®á€€á€­á€¯ API call â†’ Translation result
-Output á€€á€­á€¯ CSV/Text file á€‘á€²á€á€­á€™á€ºá€¸ (PÄli original + English side by side)
-Glossary post-edit â†’ Final academic translation corpus

á€”á€±á€¬á€€á€ºá€‘á€•á€ºá€›á€¾á€„á€ºá€¸á€•á€¼á€á€»á€€á€º
"-PÄli text â†’ split_chunks.py (â‰¤8k tokens)
- Translation via API â†’ CSV (pali + english)
- Post-edit glossary enforcement
- QA report (token ratio, glossary consistency, diacritic preservation)"

---
### âœ… á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º

Text á€€á€­á€¯ chunk á€œá€¯á€•á€ºá€•á€« (â‰¤8k tokens)

Glossary á€á€á€ºá€™á€¾á€á€ºá€•á€« (Academic terms)

Prompt design (system + user)

API call (OpenAI Responses API)

Post-edit (consistency check, term replace)

Output corpus á€¡á€–á€¼á€…á€º á€…á€¯á€†á€±á€¬á€„á€ºá€¸á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸

---

## á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá€á€²á€· á€•á€¼á€¿á€”á€¬á€™á€»á€¬á€¸ (10)

### (1) Token á€¡á€€á€”á€·á€ºá€¡á€á€á€ºá€œá€½á€”á€ºá€á€¼á€„á€ºá€¸ (stealth overflow)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: á€™á€„á€ºá€¸ á€™á€°á€›á€„á€ºá€¸ PÄli 8k á€‘á€²á€á€­á€¯á€· á€á€„á€ºá€•á€±á€™á€šá€·á€º, system + glossary + instructions + formatting á€‘á€Šá€·á€ºá€œá€­á€¯á€€á€ºá€á€²á€·á€¡á€á€« á€…á€¯á€…á€¯á€•á€±á€«á€„á€ºá€¸ 8k á€€á€»á€±á€¬á€ºá€á€½á€¬á€¸á€”á€­á€¯á€„á€ºá€á€šá€º â†’ truncate/á€¡á€™á€¾á€¬á€¸á€•á€±á€«á€ºá€”á€­á€¯á€„á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Chunking target á€€á€­á€¯ ~6.5â€“7.5k tokens á€¡á€±á€¬á€€á€ºá€‘á€¬á€¸á€•á€¼á€®á€¸ buffer 10â€“20% á€‘á€¬á€¸á‹

glossary á€€á€­á€¯ short canonical list + external reference (e.g., â€œuse the following mappingâ€¦â€) á€œá€¯á€•á€ºá€•á€¼á€®á€¸ prompt á€€á€­á€¯á€á€­á€¯á€á€„á€ºá€¸á€…á€±á‹

API response â€œfinish_reasonâ€ á€…á€…á€ºáŠ truncate á€–á€¼á€…á€ºá€›á€„á€º auto-retry with smaller chunká‹


### (2) Glossary á€™á€œá€­á€¯á€€á€ºá€–á€¼á€…á€ºá€á€¼á€„á€ºá€¸ / á€”á€¬á€›á€®á€¡á€œá€­á€¯á€€á€ºá€¡á€á€¯á€¶á€¸ (inconsistent term renderings)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: dhamma, saá¹…khÄra, paÃ±Ã±Ä á€…á€á€²á€· polysemy á€€á€¼á€±á€¬á€„á€·á€º context á€™á€á€°á€›á€„á€º gloss á€¡á€•á€¼á€±á€¬á€„á€ºá€¸á€¡á€œá€²á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºáŠ chunk á€á€…á€ºá€á€¯á€•á€¼á€®á€¸á€á€…á€ºá€á€¯ term á€™á€á€°á‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Glossary with rules: â€œDefault = X; if context=Y â‡’ Zâ€ á€•á€¯á€¶á€…á€¶á€”á€¾á€„á€·á€º á€…á€Šá€ºá€¸á€™á€»á€‰á€ºá€¸á€‘á€Šá€·á€ºá‹

Post-edit terminology normalizer (regex/lookup table) á€œá€¾á€Šá€ºá€·á€á€¯á€¶á€¸á‹

QA pass á€á€…á€ºá€á€¯á€™á€¾á€¬ key terms á€€á€­á€¯ á€–á€±á€¬á€ºá€‘á€¯á€á€ºá€•á€¼á€®á€¸ cross-chunk alignment á€…á€…á€ºá‹


### (3) Hallucination / á€¡á€–á€±á€«á€ºá€™á€²á€·á€™á€¼á€¾á€±á€¬á€€á€ºá€‘á€¬á€¸á€á€»á€€á€º

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: á€¡á€á€»á€­á€¯á€· á€…á€¬á€•á€­á€¯á€’á€ºá€á€½á€±á€™á€¾á€¬ model á€€ á€•á€­á€¯á€•á€¼á€®á€¸á€›á€±á€¸á€•á€¼á€®á€¸ commentary/expansion á€‘á€Šá€·á€ºá€”á€­á€¯á€„á€ºá€á€šá€º (especially verseâ†’prose)à¥¤
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

System prompt á€‘á€² â€œNo additions, no commentaryâ€”translation onlyâ€ á€œá€€á€ºá€á€¶á‹

Output post-check: length ratio (EN words vs PÄli tokens) thresholds á€á€á€ºá€™á€¾á€á€ºá€•á€¼á€®á€¸ over-expansion á€á€½á€±á€€á€­á€¯ flag/redoá‹


### (4) Context á€á€»á€­á€¯á€¸á€–á€±á€¬á€€á€ºá€á€¼á€„á€ºá€¸ (cross-chunk cohesion)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: á€á€®á€á€±á€«á€„á€ºá€¸/á€”á€±á€¬á€€á€ºá€€á€¼á€±á€¬á€„á€ºá€¸á€á€…á€ºá€á€¯á€€ á€á€…á€ºá€á€¼á€¬á€¸ chunk á€‘á€² á€›á€¾á€­á€”á€±á€›á€¬áŠ parallel passage á€†á€€á€ºá€œá€€á€ºá€¡á€“á€­á€•á€¹á€•á€«á€šá€º á€•á€»á€€á€ºá€”á€­á€¯á€„á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Chunk á€™á€œá€¯á€•á€ºá€™á€® semantic boundaries (verse/stanza/paragraph) á€€á€­á€¯ á€¡á€›á€„á€ºá€á€½á€²á‹

Consecutive chunks á€™á€¾á€¬ previous-chunk summary (brief) á€€á€­á€¯ few lines á€‘á€Šá€·á€ºá€•á€±á€¸ (context scaffold) â€” token buffer á€‘á€²á€…á€­á€™á€ºá€¸á€…á€­á€™á€ºá€¸á‹

Consolidation pass: á€¡á€†á€¯á€¶á€¸á€™á€¾á€¬ stitcher script á€”á€²á€· cohesive edit á€œá€¯á€•á€ºá‹


### (5) Unicode/Diacritics á€•á€¼á€¿á€”á€¬ (lossy normalization)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: PÄli roman diacritics (Ä Ä« Å« á¹ƒ á¹… Ã± á¹­ á¸ á¹‡ â€¦) á€á€½á€± NFD/NFC á€™á€á€°áŠ á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º á€–á€­á€¯á€„á€º encoding á€™á€á€°á€œá€­á€¯á€· garbling á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Input á€€á€­á€¯ UTF-8 / NFC normalize (Python unicodedata.normalize).

API å‰/å á€•á€±á€«á€ºá€™á€¾á€¬ round-trip check (hash/len) á€á€á€ºá€™á€¾á€á€ºá‹

Output á€€á€­á€¯á€œá€Šá€ºá€¸ NFC normalize + lossless storage (UTF-8).


### (6) Meter/Poetic structure á€•á€»á€€á€ºá€á€½á€¬á€¸á€á€¼á€„á€ºá€¸

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: Verse/metrical cues á€•á€»á€€á€ºá€•á€¼á€®á€¸ meaning drift á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Prompt á€›á€²á€· instructions á€‘á€² â€œPreserve line breaks and stanza boundaries; reflect enjambment cautiouslyâ€ á€‘á€Šá€·á€ºá‹

Output formatter: line-preserving translation (1:1 line map) option á€‘á€Šá€·á€ºá€á€²á€·á‹


### (7) Determinism á€™á€á€Šá€ºá€„á€¼á€­á€™á€º (style drift)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: temperature defaults á€™á€Šá€¾á€­á€œá€­á€¯á€· á€á€…á€ºá€á€«á€á€…á€ºá€›á€¶ tone/wording á€œá€²áŠ sessionë§ˆë‹¤ variation á€›á€¾á€­á‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

temperature=0â€“0.2 / top_p=0.1â€“0.3 á€á€á€ºá€™á€¾á€á€ºá‹

seed available á€–á€¼á€…á€ºá€›á€„á€º á€á€á€ºá€™á€¾á€á€º (OpenAI responses APIs á€™á€¾á€¬ deterministic á€™á€°á€œá€á€”á€ºá€–á€­á€¯á€¸á€¡á€œá€¬á€¸á€¡á€œá€¬á€€ á€™á€á€Šá€ºá€„á€¼á€­á€™á€ºá€”á€­á€¯á€„á€º)á‹

Post-edit style guide + formatter run (Oxford comma, capitalization policy, italicization rules for PÄli terms).


### (8) Rate limits / retry logic á€™á€›á€¾á€­á€á€¼á€„á€ºá€¸

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: Large corpora á€™á€»á€¬á€¸ run á€á€±á€¬á€¡á€á€« 429 / timeout / transient errors á€€á€¼á€¯á€¶á€”á€­á€¯á€„á€º â†’ pipeline á€›á€•á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Exponential backoff + jitter á€”á€²á€· retry;

idempotent job queue (per-chunk state) á€‘á€¬á€¸áŠ fail chunk only retry;

throttle (QPS/TPM) á€€á€­á€¯ provider docs á€¡á€á€­á€¯á€„á€ºá€¸ á€á€»á€­á€”á€ºá‹


### (9) Cost drift (output-heavy á€•á€¼á€”á€ºá€•á€±á€«á€ºá€™á€¾á€¯)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: Verseâ†’explanatory prose á€¡á€–á€¼á€…á€º output tokens á€™á€»á€¬á€¸á€•á€¼á€®á€¸ á€€á€¯á€”á€ºá€€á€»á€…á€›á€­á€á€º á€‘á€½á€¬á€¸á‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Instruction: â€œTranslate concisely; no paraphrase beyond lexical equivalence.â€

Output token watchdog: max_tokens reasonable cap + length-ratio guard;

Cost dashboard: per-chunk cost log + alert thresholdsá‹


### (10) QA/á€á€˜á€±á€¬á€á€›á€¬á€¸ á€¡á€™á€¾á€¬á€¸á€šá€½á€„á€ºá€¸ (doctrinal nuance errors)

á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²: Terms like sammÄsambuddha, arahant, nibbÄna, dhamma á€…á€á€¬á€á€½á€± context-sensitive â€” wrong register/nuance á€–á€¼á€…á€ºá€”á€­á€¯á€„á€ºá‹
á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º:

Two-pass QA: (a) MT pass; (b) glossary-aware checker + doctrinal spot-rules (e.g., dhamma â†’ â€œthe Teachingâ€ vs â€œphenomenaâ€ by context cues).

Human-in-the-loop on flagged lines only (active-learning workflow).

Issue registry á€á€Šá€ºá€†á€±á€¬á€€á€ºá€•á€¼á€®á€¸ recurring mistakes á€€á€­á€¯ ruleset á€‘á€²á€á€­á€¯á€· update.


## á€•á€¼á€¿á€”á€¬á€á€…á€ºá€á€»á€€á€ºá€œá€»á€¾á€„á€º á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€”á€Šá€ºá€¸ áƒ á€™á€»á€­á€¯á€¸

### ğŸ“Œ Problem 1 â€” Token á€¡á€€á€”á€·á€ºá€¡á€á€á€ºá€œá€½á€”á€ºá€á€¼á€„á€ºá€¸ (overflow)
â‘  Preventive: Chunker á€á€½á€„á€º safe margin á€‘á€¬á€¸

Max 8k á€™á€á€¯á€¶á€¸á€•á€² 7kâ€“7.5k tokens á€¡á€–á€¼á€…á€º á€€á€á€ºá€‘á€¬á€¸ (prompt + glossary token overhead á€á€¶á€”á€­á€¯á€„á€ºá€–á€­á€¯á€·)á‹

â‘¡ Alternative: Tokenizer-based splitting

tiktoken á€á€¯á€¶á€¸á€•á€¼á€®á€¸ input á€€á€­á€¯ á€…á€…á€ºá€á€­á€¯á€„á€ºá€¸ á€…á€…á€ºá€á€­á€¯á€„á€ºá€¸ token-based hard split á€œá€¯á€•á€ºá€á€¼á€„á€ºá€¸ (character heuristics á€™á€á€¯á€¶á€¸)á‹

â‘¢ Fallback: Auto-retry smaller chunk

API á€€ truncate á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º error á€•á€±á€«á€ºá€œá€¬á€›á€„á€º script á€‘á€²á€™á€¾á€¬ smaller sub-chunk (e.g. 5k tokens) auto-retry á€œá€¯á€•á€ºá€…á€±á‹


### ğŸ“Œ Problem 2 â€” Glossary á€™á€œá€­á€¯á€€á€ºá€–á€¼á€…á€ºá€á€¼á€„á€ºá€¸ / inconsistency
â‘  Preventive: Prompt á€‘á€² glossary mapping á€€á€­á€¯ bullet-list + â€œalways enforceâ€ á€á€á€ºá€™á€¾á€á€º

e.g. Glossary: paÃ±Ã±Ä â†’ wisdom; saá¹…khÄra â†’ formations; â€¦

â‘¡ Alternative: Post-processing rule engine

Translation result á€á€½á€±á€€á€­á€¯ regex/lookup á€”á€²á€· forced replacement (synonym â†’ canonical term)á‹

â‘¢ Fallback: QA check with flagging

Script á€á€…á€ºá€á€¯á€”á€²á€· glossary term á€á€½á€± á€™á€‘á€­á€•á€ºá€™á€•á€±á€«á€ºá€á€¬á€á€½á€± flag only á€œá€¯á€•á€ºá€•á€¼á€®á€¸ human-review á€¡á€†á€„á€·á€ºá€á€„á€ºá‹


### ğŸ“Œ Problem 3 â€” Hallucination (á€¡á€–á€±á€«á€ºá€™á€²á€·á€™á€¼á€¾á€±á€¬á€€á€ºá€‘á€¬á€¸á€á€»á€€á€º)
â‘  Preventive: Prompt restriction

System instruction á€‘á€² â€œNo commentary, translation only, no paraphrase.â€ á€†á€­á€¯á€•á€¼á€®á€¸ á€›á€¾á€„á€ºá€¸á€›á€¾á€„á€ºá€¸á€á€„á€ºá‹

â‘¡ Alternative: Length ratio watchdog

PÄli tokens vs English words ratio (á€¥á€•á€™á€¬ >2.2) á€†á€­á€¯á€›á€„á€º suspect á€œá€¯á€•á€ºá€•á€¼á€®á€¸ re-translate auto-triggerá‹

â‘¢ Fallback: Post-edit filter

Output á€‘á€² [Translatorâ€™s noteâ€¦] / bracket expansions á€á€½á€± á€›á€¾á€­á€›á€„á€º regex á€–á€¼á€„á€·á€º á€–á€šá€ºá€•á€¼á€®á€¸ QA flag á€‘á€•á€ºá€á€„á€ºá‹


### ğŸ“Œ Problem 4 â€” Context á€á€»á€­á€¯á€¸á€–á€±á€¬á€€á€ºá€á€¼á€„á€ºá€¸ (cross-chunk cohesion)
â‘  Preventive: Semantic boundary chunking

PÄli file á€€á€­á€¯ stanza/paragraph/heading á€¡á€œá€­á€¯á€€á€º á€á€½á€² (logic break á€™á€–á€¼á€á€º)á‹

â‘¡ Alternative: Context scaffold

Chunk á€á€…á€ºá€á€¯á€‘á€²á€™á€¾á€¬ â€œPrevious stanza summary: â€¦â€ á€œá€­á€¯á€¡á€á€­á€¯á€á€»á€¯á€•á€ºá€‘á€Šá€·á€ºá€•á€±á€¸ (2â€“3 lines)á‹

â‘¢ Fallback: Post-stitcher review

Translation outputs á€€á€­á€¯ aligner script á€”á€²á€· á€…á€¯á€•á€±á€«á€„á€ºá€¸á€€á€¼á€Šá€·á€º â†’ cohesive inconsistency á€á€½á€± flag & human adjustá‹


### ğŸ“Œ Problem 5 â€” Unicode/Diacritics á€•á€¼á€¿á€”á€¬
â‘  Preventive: Normalize all inputs/outputs to UTF-8 NFC

Python unicodedata.normalize("NFC") á€á€¯á€¶á€¸á‹

â‘¡ Alternative: Diacritic preservation tests

Hash/token counts before & after â†’ mismatch á€–á€¼á€…á€ºá€›á€„á€º error flagá‹

â‘¢ Fallback: Automated repair

Output á€‘á€²á€™á€¾á€¬ lost diacritics (Äâ†’a, Ã±â†’n) á€á€½á€±á€€á€­á€¯ regex mapping á€”á€²á€· restore (backup dictionary á€á€¯á€¶á€¸)á‹

### âœ… á€¡á€€á€»á€‰á€ºá€¸á€á€»á€¯á€•á€º

á€•á€‘á€™ á… á€á€»á€€á€º á€¡á€á€½á€€á€º

Problem 1 â†’ (Margin chunking, tokenizer-based split, auto-retry)

Problem 2 â†’ (Glossary in prompt, post-edit rules, QA flagging)

Problem 3 â†’ (Strict prompt, length ratio guard, hallucination filter)

Problem 4 â†’ (Semantic chunking, context scaffold, post-stitcher)

Problem 5 â†’ (UTF-8 NFC normalize, hash/token preservation, diacritic repair)

-----------

### ğŸ“Œ Problem 6 â€” Meter/Poetic Structure á€•á€»á€€á€ºá€á€½á€¬á€¸á€á€¼á€„á€ºá€¸

â‘  Preventive â€” Line-preserving Prompt & IO

System á€‘á€² â€œPreserve original line breaks and stanza boundaries; keep 1:1 line mappingâ€ á€‘á€Šá€·á€ºá‹

Input á€€á€­á€¯ stanza/line ID á€–á€¼á€„á€·á€º tag á€œá€¯á€•á€ºá€•á€« ([L001] â€¦) â†’ Output á€™á€¾á€¬á€œá€Šá€ºá€¸ á€¡á€²á€’á€® ID á€™á€»á€¬á€¸ á€¡á€•á€¼á€”á€ºá€‘á€¯á€á€ºá€…á€±á‹

Chunker á€™á€¾á€¬ stanza boundary á€€á€­á€¯ á€™á€–á€¼á€á€ºá€•á€« (blank-line split + NFC normalize)á‹

â‘¡ Alternative â€” Dual-output Mode

Prompt: â€œReturn two blocks: (A) line-preserving translation (1:1), (B) smoothed prose.â€

Editing/Publication á€á€½á€„á€º (A) á€€á€­á€¯ Canonical, (B) á€€á€­á€¯ readable commentary á€¡á€–á€¼á€…á€º á€á€®á€¸á€á€”á€·á€ºá€á€¯á€¶á€¸á‹

â‘¢ Fallback â€” Post-reflow Fixer

Translation á€”á€±á€¬á€€á€ºá€á€…á€ºá€œá€¾á€Šá€·á€ºá€™á€¾á€¬ aligner script (diff by line count) á€á€¯á€¶á€¸á€•á€¼á€®á€¸ line count mismatch á€á€½á€±á€€á€­á€¯ auto reflow á€á€­á€¯á€·á€™á€Ÿá€¯á€á€º flag â†’ minimal re-chunk + re-translate á€•á€¼á€”á€ºá€œá€¯á€•á€ºá‹


### ğŸ“Œ Problem 7 â€” Determinism á€™á€á€Šá€ºá€„á€¼á€­á€™á€º (style drift / synonym drift)

â‘  Preventive â€” Low-variance Decoding & Style Guard

temperature=0â€“0.2, top_p=0.1â€“0.3áŠ á€›á€›á€½á€­á€•á€«á€€ seed á€á€á€ºá€™á€¾á€á€ºá€á€¼á€„á€ºá€¸á‹

System á€‘á€² style guide á€‘á€Šá€·á€º (formal, concise, academic; no rhetorical flourishes)á‹

Glossary priority á€á€á€ºá€™á€¾á€á€º (â€œWhen multiple renderings exist, prefer the glossary form.â€)á‹

â‘¡ Alternative â€” Constrained Post-Edit

postedit_terms.py á€™á€¾á€¬ synonym tables (e.g., knowledgeâ†’wisdom) á€‘á€•á€ºá€á€­á€¯á€¸áŠ casing/punctuation policy (Oxford comma, italicization) á€á€Šá€ºá€†á€±á€¬á€€á€ºá‹

Unit tests (doctests) á€–á€¼á€„á€·á€º common phrases/terms output á€€á€­á€¯ á€…á€¯á€¶á€…á€™á€ºá€¸á‹

â‘¢ Fallback â€” Memory Priming / Few-shot

Chunk á€á€…á€ºá€…á€€á€ºá€…á€® á€™á€…á€›á€á€±á€¸á€á€„á€º short few-shot examples (PÄliâ†’EN pairs) á€‘á€Šá€·á€ºá€•á€¼á€®á€¸ tone lock-iná‹

Drift á€á€½á€± á€á€½á€±á€·á€›á€„á€º offending chunk only re-run with extended few-shot + stricter instructionsá‹


### ğŸ“Œ Problem 8 â€” Rate Limits / Transient Errors / Timeouts

â‘  Preventive â€” Throttling & Budgeting

Provider TPM/QPS á€€á€­á€¯ config file á€™á€¾á€¬á€á€á€ºá€™á€¾á€á€ºá€•á€¼á€®á€¸ token budget estimator á€”á€²á€· á€€á€¼á€­á€¯á€á€„á€ºá€á€½á€€á€ºá‹

Calls á€€á€¼á€¬á€¸ delay (e.g., 600â€“800ms) á€‘á€¬á€¸áŠ large jobs á€€á€­á€¯ batched scheduling (night windows) á€á€¯á€¶á€¸á‹

â‘¡ Alternative â€” Resilient Client

Exponential backoff + jitteráŠ idempotent retries (same chunk_id á€›á€¾á€­á€›á€„á€º overwrite-safe)á‹

Circuit breaker (continuous 429/5xx > N times â†’ cool-down 5â€“10 min) + logging/alertsà¥¤

â‘¢ Fallback â€” Queue & Resume

Per-chunk state file (pending/ok/fail) á€‘á€¬á€¸á€•á€¼á€®á€¸ process interrupt á€–á€¼á€…á€ºá€›á€„á€º resume from last goodá‹

Secondary model (e.g., 4o-mini) á€€á€­á€¯ fallback tier á€¡á€–á€¼á€…á€º auto-switch á€á€á€ºá€™á€¾á€á€ºá‹


### ğŸ“Œ Problem 9 â€” Cost Drift (output too long / paraphrase inflation)

â‘  Preventive â€” Output Caps & Concision Rule

Prompt: â€œTranslate only; avoid paraphrase; keep concise.â€

max_tokens á€€á€­á€¯ reasonable cap (e.g., 1â€“2Ã— input tokens) á€•á€¼á€¯á€œá€¯á€•á€ºá‹

Length-ratio watchdog (EN words / PÄli token_est) á€€á€­á€¯ pipeline á€‘á€²á€™á€¾á€¬ threshold (e.g., 2.2) á€á€á€ºá€™á€¾á€á€ºá‹

â‘¡ Alternative â€” Two-pass Compression

Pass-1: raw faithful translation; Pass-2: terminology-preserving compression (â€œreduce redundancies; keep doctrinal terms intactâ€).

Long outputs á€á€½á€±á€€á€­á€¯ sentence-level á€á€½á€²á€•á€¼á€®á€¸ á€á€­á€¯á€á€±á€¬á€„á€ºá€¸á€¡á€±á€¬á€„á€º re-ask (same chunk, smaller units)á‹

â‘¢ Fallback â€” Cost Dashboard & Auto-Clamp

Per-chunk cost log (input/output tokens Ã— price) + daily budget alertsà¥¤

Ratio/price á€¡á€œá€½á€”á€ºá€™á€»á€¬á€¸á€á€²á€· chunks á€€á€­á€¯ auto re-run with stricter cap (shorter max_tokens, stronger â€œno paraphraseâ€ reminder)á‹


### ğŸ“Œ Problem 10 â€” Doctrinal Nuance Errors (semantic misrendering)

â‘  Preventive â€” Contextual Glossary Rules

Glossary á€€á€­á€¯ rule-based á€œá€¯á€•á€º: dhamma â†’ default â€œthe Teachingâ€; if context = phenomenology/abhidhamma cues â‡’ â€œphenomenaâ€.

Prompt á€‘á€² â€œWhen unsure, choose the conservative, canonical renderingâ€ + cite standard conventions (PTS/CPD).

â‘¡ Alternative â€” Heuristic Detectors & Flags

Rule-checks: key terms á€œá€²á€œá€¾á€šá€ºá€™á€¾á€¯ (e.g., arahant â‰  saint), wrong capitalization of proper nouns, Sangha vs saá¹…gha distinctioná‹

QA script á€™á€¾á€¬ keyword-in-window (Â±N lines) á€”á€²á€· expected translation á€á€½á€€á€ºá€•á€¼á€®á€¸ mismatch á€á€½á€± flag onlyá‹

â‘¢ Fallback â€” Human-in-the-loop on Deltas

Flagged lines only á€€á€­á€¯ lightweight reviewer UI (CSV filter) á€‘á€²á€á€„á€º â†’ approve/fix â†’ ruleset update (active learning)á‹

Recurrent error types á€€á€­á€¯ few-shot exemplars á€‘á€Šá€·á€ºá€•á€¼á€®á€¸ prompt retrain-like effect á€›á€›á€¾á€­á€¡á€±á€¬á€„á€º iterateá‹






























### 1) Token á€¡á€€á€”á€·á€ºá€¡á€á€á€ºá€œá€½á€”á€ºá€á€¼á€„á€ºá€¸ (stealth overflow)
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** PÄli text á€€á€­á€¯ 8k á€‘á€²á€‘á€Šá€·á€ºá€•á€±á€™á€šá€·á€º, system + glossary + instructions + formatting á€‘á€Šá€·á€ºá€œá€­á€¯á€€á€ºá€á€²á€·á€¡á€á€« á€…á€¯á€…á€¯á€•á€±á€«á€„á€ºá€¸ 8k á€€á€»á€±á€¬á€ºá€”á€­á€¯á€„á€º â†’ truncate á€–á€¼á€…á€ºá€”á€­á€¯á€„á€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Chunk target á€€á€­á€¯ 6.5â€“7.5k tokens á€¡á€±á€¬á€€á€ºá€‘á€¬á€¸ buffer 10â€“20% á€‘á€¬á€¸
2. Tokenizer-based splitting (tiktoken á€á€¯á€¶á€¸)
3. API response truncate á€–á€¼á€…á€ºá€›á€„á€º auto-retry with smaller chunk

---

### 2) Glossary á€™á€œá€­á€¯á€€á€ºá€–á€¼á€…á€ºá€á€¼á€„á€ºá€¸ / inconsistency
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** dhamma, saá¹…khÄra, paÃ±Ã±Ä á€…á€á€²á€· polysemy á€€á€¼á€±á€¬á€„á€·á€º chunk á€á€…á€ºá€á€¯á€•á€¼á€®á€¸ á€á€…á€ºá€á€¯ term á€™á€á€°

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Glossary with rules: â€œDefault=X; if context=Y â‡’ Zâ€ á€á€á€ºá€™á€¾á€á€º
2. Post-edit terminology normalizer (regex/lookup table)
3. QA pass: key terms alignment check

---

### 3) Hallucination (á€¡á€–á€±á€«á€ºá€™á€²á€·á€™á€¼á€¾á€±á€¬á€€á€ºá€‘á€¬á€¸á€á€»á€€á€º)
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Translation á€‘á€²á€™á€¾á€¬ á€¡á€•á€­á€¯á€‘á€Šá€·á€ºá€”á€­á€¯á€„á€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Prompt restriction: â€œNo commentary, translation onlyâ€
2. Length ratio watchdog (EN words / PÄli tokens)
3. Post-edit filter: translatorâ€™s note, bracket expansions remove

---

### 4) Context á€á€»á€­á€¯á€¸á€–á€±á€¬á€€á€ºá€á€¼á€„á€ºá€¸ (cross-chunk cohesion)
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Chunk á€á€½á€²á€™á€™á€¾á€”á€ºá€›á€„á€º continuity á€•á€»á€€á€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Semantic boundary chunking (stanza/paragraph á€¡á€œá€­á€¯á€€á€º)
2. Context scaffold (previous-chunk summary few lines á€‘á€Šá€·á€º)
3. Post-stitcher review & aligner script

---

### 5) Unicode/Diacritics á€•á€¼á€¿á€”á€¬
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Ä Ä« Å« Ã± á¹­ á¹‡ á€…á€á€²á€· diacritics á€•á€»á€€á€ºá€”á€­á€¯á€„á€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Normalize input/output â†’ UTF-8 NFC
2. Hash/token preservation test before/after
3. Automated repair (Äâ†’a fix, Ã±â†’n fix dictionary)

---

### 6) Meter/Poetic Structure á€•á€»á€€á€ºá€á€½á€¬á€¸á€á€¼á€„á€ºá€¸
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Verse/metrical cues á€•á€»á€€á€ºá€”á€­á€¯á€„á€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Line-preserving prompt & line-ID annotation
2. Dual-output mode: (A) line-preserve, (B) prose
3. Post-reflow fixer (aligner script for line count mismatch)

---

### 7) Determinism á€™á€á€Šá€ºá€„á€¼á€­á€™á€º (style drift)
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Tone/synonym drift, sessionë§ˆë‹¤ á€•á€¼á€±á€¬á€„á€ºá€¸

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Low temperature/top_p, style guard in system prompt
2. Post-edit synonym table enforcement
3. Few-shot examples to stabilize tone

---

### 8) Rate limits / Transient Errors
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Large jobs â†’ 429, timeout

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Throttling & token budgeting
2. Exponential backoff + jitter, circuit breaker
3. Resume from state (job queue) + fallback model

---

### 9) Cost drift (output inflation)
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Model output á€¡á€œá€½á€”á€ºá€›á€¾á€Šá€º

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Prompt: â€œconcise translation onlyâ€; cap max_tokens
2. Two-pass compression (faithful â†’ concise)
3. Cost log + auto-clamp high-cost chunks

---

### 10) Doctrinal nuance errors
**á€˜á€¬á€–á€¼á€…á€ºá€™á€œá€²:** Key terms mistranslated (arahant, dhamma, nibbÄna)

**á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€á€»á€€á€º (3)**
1. Contextual glossary rules
2. QA detectors: mismatch flags, capitalization check
3. Human-in-loop for flagged lines + rule update

---

## á€”á€­á€‚á€¯á€¶á€¸á€á€»á€¯á€•á€º
- Pipeline á€€á€­á€¯ 6 á€¡á€†á€„á€·á€ºá€”á€²á€· á€œá€¯á€•á€ºá€•á€« (chunk, glossary, prompt, API call, post-edit, QA)
- á€•á€¼á€¿á€”á€¬ áá€ á€á€»á€€á€ºá€€á€­á€¯ áƒ á€”á€Šá€ºá€¸á€…á€® á€–á€¼á€±á€›á€¾á€„á€ºá€¸á€–á€­á€¯á€· á€•á€¼á€„á€ºá€‘á€¬á€¸á€•á€«
- Output á€€á€­á€¯ reproducible corpus á€¡á€–á€¼á€…á€º á€á€­á€™á€ºá€¸á€†á€Šá€ºá€¸á€•á€¼á€®á€¸ academic research á€¡á€á€½á€€á€º á€á€¯á€¶á€¸á€”á€­á€¯á€„á€ºá€•á€«á€á€Šá€ºá‹

